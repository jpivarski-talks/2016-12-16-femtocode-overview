\documentclass{beamer}

%
% Choose how your presentation looks.
%
% For more themes, color themes and font themes, see:
% http://deic.uab.es/~iblanes/beamer_gallery/index_by_theme.html
%
\mode<presentation>
{
  \usetheme{default}      % or try Darmstadt, Madrid, Warsaw, ...
  \usecolortheme{default} % or try albatross, beaver, crane, ...
  \usefonttheme{default}  % or try serif, structurebold, ...
  \setbeamertemplate{navigation symbols}{}
  \setbeamertemplate{caption}[numbered]
  \setbeamertemplate{footline}[page number]
  \setbeamercolor{frametitle}{fg=white}
  \setbeamercolor{footline}{fg=black}
} 

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{tikz}
\usepackage{listings}
\usepackage{courier}
\usepackage{minted}

\xdefinecolor{darkblue}{rgb}{0.1,0.1,0.7}
\xdefinecolor{darkorange}{rgb}{0.8,0.5,0}
\xdefinecolor{dianablue}{rgb}{0.18,0.24,0.31}
\definecolor{commentgreen}{rgb}{0,0.6,0}
\definecolor{stringmauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},      % choose the background color
  basicstyle=\ttfamily\small,         % size of fonts used for the code
  breaklines=true,                    % automatic line breaking only at whitespace
  captionpos=b,                       % sets the caption-position to bottom
  commentstyle=\color{commentgreen},  % comment style
  escapeinside={\%*}{*)},             % if you want to add LaTeX within your code
  keywordstyle=\color{blue},          % keyword style
  stringstyle=\color{stringmauve},    % string literal style
  showstringspaces=false,
  showlines=true
}

\lstdefinelanguage{scala}{
  morekeywords={abstract,case,catch,class,def,%
    do,else,extends,false,final,finally,%
    for,if,implicit,import,match,mixin,%
    new,null,object,override,package,%
    private,protected,requires,return,sealed,%
    super,this,throw,trait,true,try,%
    type,val,var,while,with,yield},
  otherkeywords={=>,<-,<\%,<:,>:,\#,@},
  sensitive=true,
  morecomment=[l]{//},
  morecomment=[n]{/*}{*/},
  morestring=[b]",
  morestring=[b]',
  morestring=[b]"""
}

\title[2016-12-16-femtocode-overview]{Femtocode Overview}
\author{Jim Pivarski}
\institute{Princeton University -- DIANA}
\date{December 16, 2016}

\begin{document}

\logo{\pgfputat{\pgfxy(0.11, 8)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}}}\pgfputat{\pgfxy(0.11, -0.6)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\includegraphics[height=0.99 cm]{diana-hep-logo.png}\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (4.9 cm, 1 cm);}}}}

\begin{frame}
  \titlepage
\end{frame}

\logo{\pgfputat{\pgfxy(0.11, 8)}{\pgfbox[right,base]{\tikz{\filldraw[fill=dianablue, draw=none] (0 cm, 0 cm) rectangle (50 cm, 1 cm);}\includegraphics[height=1 cm]{diana-hep-logo.png}}}}

% Uncomment these lines for an automatically generated outline.
%\begin{frame}{Outline}
%  \tableofcontents
%\end{frame}

\begin{frame}{Essential and accidental complexity}
\vspace{0.25 cm}
\textcolor{darkorange}{\bf End-user physics analysis \underline{must} include the following:}
\begin{description}
\item[\bf big data pull:] probably with on-the-fly filters and transformations, given the scale of the data,
\item[\bf manipulations:] at least plotting, but probably fitting, unfolding, cross-comparisons, machine learning, etc.
\end{description}

\vfill
\begin{uncoverenv}<2->
\textcolor{darkorange}{\bf Currently, most analyses also include:}
\begin{description}
\item[\bf private skim:] intermediate-sized dataset with more fields than necessary.
\begin{itemize}
\item Since the big data pull takes so long, fields that {\it might} be needed are included as a hedge.
\item This makes the big data pull bigger.

\textcolor{gray}{(The more skim you have, the more you need!)}
\end{itemize}
\end{description}
\end{uncoverenv}
\end{frame}

\begin{frame}{Reducing dataset size early}
\begin{center}
\only<1>{\includegraphics[width=0.8\linewidth]{pseudoplot.pdf}}
\only<2>{\includegraphics[width=0.8\linewidth]{pseudoplot2.pdf}}
\end{center}

Ideally, data should go directly from the collaboration-wide store (e.g.\ MiniAOD) into plots, fits, or machine learning algorithms, rapidly enough that there's no temptation to overstock the big data pull.
\end{frame}

\begin{frame}{Industry {\it expects} interactive analysis}

Business intelligence has traditionally been interactive; there's a race to provide interactivity with Big Data backends:

\begin{center}
\textcolor{blue}{Ibis, Impala, Kudu, Drill, \ldots}
\end{center}

all aim to yield sub-second results from terabytes or petabytes of data.

\vfill
\textcolor{darkorange}{\bf Shouldn't we?}
\end{frame}

\begin{frame}{How could this even be possible?}
\vspace{0.5 cm}
\textcolor{darkorange}{\bf How could a week-long GRID job be reduced to seconds?}

\vspace{0.5 cm}
\begin{columns}[t]
\column{0.5\linewidth}
\textcolor{darkblue}{\underline{\bf GRID job}}

\begin{itemize}
\item Includes data fields that {\it might} be useful.

\item Framework reconstructs whole C++ objects, regardless of whether they're split in ROOT: loading {\it dozens} of unused fields.

\item Bad choices in user's C++.

\item Finding storage for and moving the big output files.
\end{itemize}

\column{0.5\linewidth}
\textcolor{darkblue}{\underline{\bf Interactive query}}

\begin{itemize}
\item Limited to fields mentioned in the query.

\item Only loads the attributes mentioned in the query: rarely more than 5--10.

\item Can employ JIT or other optimizations.

\item Can cache frequently requested fields or subexpressions among users.
\end{itemize}
\end{columns}

\vspace{0.5 cm}
\textcolor{gray}{(Not to mention {\it user's time} needed to write and test the code.)}
\end{frame}

\begin{frame}{}
\begin{center}
\textcolor{darkblue}{\huge But\ldots}
\end{center}
\end{frame}

\begin{frame}[fragile]{Physics data are different}
\vspace{0.5 cm}
Most datasets in industry are (the equivalent of) flat ntuples:
\begin{itemize}
\item SQL tables
\item OLAP hypercubes
\item exceptions are often handled with user-defined functions
(e.g.\ lat, lon $\to$ zip code, followed by ntuple analysis on zip codes).
\end{itemize}

\vfill
\begin{uncoverenv}<2->
Modern SQL engines are capable of nested structure, but have no functions for dealing with the structure other than exploding it.

\vspace{0.25 cm}
\textcolor{darkblue}{Physics equivalent:} doing all analysis with TTreeFormula:

\begin{lstlisting}[language=c]
ntuple->Draw("tracks[].hits[].residual >> hresid");
\end{lstlisting}
\end{uncoverenv}
\end{frame}

\begin{frame}{Physics data are different}
\vspace{0.25 cm}
{\bf Spark has two options:}
\begin{enumerate}
\item SQL-style (flat) analysis with DataFrames,
\item General analysis with RDDs.
\end{enumerate}
When I asked Michael Armbridge (Databricks) about this, he said the goal of DataFrames was to cover ``95\% of the use-cases.''

\vfill
Physics analysis with flat ntuples is within their ``95\%,'' but something like this isn't:
\begin{center}
\begin{minipage}{0.9\linewidth}
\textcolor{darkblue}{``Momentum of the track with the most hits with $|\eta|$ $<$ 2.4.''}
\end{minipage}
\end{center}

\vfill
Restricting to flat ntuple analysis would require more private skims,
less interactive analysis!
\end{frame}





\end{document}
